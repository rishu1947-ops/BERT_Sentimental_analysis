{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a6151cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bz2\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4871d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sentiment model...\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the model (this can take a moment)\n",
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "711cbea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"bittlingmayer/amazonreviews\")\n",
    "train_file = os.path.join(path, 'train.ft.txt')\n",
    "compressed_file = os.path.join(path, 'train.ft.txt.bz2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(train_file):\n",
    "    \n",
    "    with bz2.open(compressed_file, 'rb') as f_in, open(train_file, 'wb') as f_out:\n",
    "        f_out.write(f_in.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e5d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading a sample of reviews...\n"
     ]
    }
   ],
   "source": [
    "reviews_data = []\n",
    "with open(train_file, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 1000:  # Stop after 1000 reviews\n",
    "            break\n",
    "        # The line format is: __label__X Review text...\n",
    "        label = int(line[9]) # Directly grab the rating number\n",
    "        review = line[11:].strip()\n",
    "        reviews_data.append({'rating': label, 'review': review})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f2d2dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(reviews_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e086be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    # Truncate text to fit the model's max length\n",
    "    tokens = tokenizer.encode(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    result = model(tokens)\n",
    "    # The model outputs 0-4, so we add 1 for a 1-5 star rating\n",
    "    return torch.argmax(result.logits).item() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0a259c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_binary(score):\n",
    "    if score <= 2:  # 1 and 2 stars are negative\n",
    "        return 1\n",
    "    elif score >= 4: # 4 and 5 stars are positive\n",
    "        return 2\n",
    "    else: # 3 stars is neutral, which we'll treat as neither class.\n",
    "          # We can map it to 0 or 3 so it's always wrong in accuracy check.\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd58c02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment... (this may take a minute)\n"
     ]
    }
   ],
   "source": [
    "df['sentiment'] = df['review'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97666f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis complete. Here are the first few results:\n",
      "   rating                                             review  sentiment\n",
      "0       2  Stuning even for the non-gamer: This sound tra...          5\n",
      "1       2  The best soundtrack ever to anything.: I'm rea...          5\n",
      "2       2  Amazing!: This soundtrack is my favorite music...          5\n",
      "3       2  Excellent Soundtrack: I truly like this soundt...          5\n",
      "4       2  Remember, Pull Your Jaw Off The Floor After He...          5\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3736a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7ba1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = os.path.join(path, 'test.ft.txt')\n",
    "compressed_test_file = os.path.join(path, 'test.ft.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c31c8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(test_file):\n",
    "    print(\"Decompressing test dataset...\")\n",
    "    with bz2.open(compressed_test_file, 'rb') as f_in, open(test_file, 'wb') as f_out:\n",
    "        f_out.write(f_in.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7831ec8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading a sample of test reviews...\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading a sample of test reviews...\")\n",
    "test_data = []\n",
    "with open(test_file, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 1000:  # Using a sample of 1000 for speed\n",
    "            break\n",
    "        # True label is 1 (negative) or 2 (positive)\n",
    "        true_label = int(line[9])\n",
    "        review = line[11:].strip()\n",
    "        test_data.append({'true_label': true_label, 'review': review})\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3c8638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model on test data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Running model on test data...\")\n",
    "test_df['predicted_5_star'] = test_df['review'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "02e34111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_binary(score):\n",
    "    if score <= 2: return 1  # Negative\n",
    "    if score >= 4: return 2  # Positive\n",
    "    return 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a93d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predicted_binary'] = test_df['predicted_5_star'].apply(map_to_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143ca30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Evaluation (Corrected) ---\n",
      "Model Accuracy on Binary Task: 88.50%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_df['true_label'], test_df['predicted_binary'])\n",
    "print(f\"Model Accuracy on Binary Task: {accuracy:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
